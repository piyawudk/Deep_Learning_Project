{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buehBEIZjbKn"
      },
      "source": [
        "### **11-layers Mnist CNN 99.09% accuracy**\n",
        "\n",
        "**Piyawud Koonmanee 63110119**\\\n",
        "Date of Submission: 8-Mar-2022\\\n",
        "Runtime: \n",
        "- ~23 seconds using Nvidia T4 (from Google Colab)\n",
        "- ~4 minute 32 seconds using Intel Core i5-8300H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_-OgDu4jbK7",
        "outputId": "4c09d6b2-f305-4843-cb21-50c5db304a48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ],
      "source": [
        "%reset # clear the variables\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from tensorflow.keras import Model, layers, Sequential\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# setup the random state (seed) to obtain reproducible results\n",
        "np.random.seed(63110119) \n",
        "random.seed(63110119)\n",
        "tf.random.set_seed(63110119)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq7_XP8ejbLD",
        "outputId": "ea089034-e526-4085-e184-13a2733a23b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST Dataset Shapes:\n",
            "x_train: (60000, 28, 28, 1)\n",
            "y_train: (60000,)\n",
            "x_test: (10000, 28, 28, 1)\n",
            "y_test: (10000,)\n"
          ]
        }
      ],
      "source": [
        "# prepare dataset\n",
        "\n",
        "# MNIST dataset parameters\n",
        "num_classes = 10 # total classes (0-9 digits)\n",
        "num_features = 784 # data features (img shape: 28 X 28 = 784)\n",
        "\n",
        "# import and load MNIST data, split between test and train datasets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# convert pixel values to float32\n",
        "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
        "\n",
        "# normalize image pixcel values from [0, 255] to [0, 1]\n",
        "x_train, x_test = x_train/255.0 , x_test/255.0\n",
        "\n",
        "# set gray scale color channel (to make it work for Conv2D since it needs the dimenstion to be 4)\n",
        "x_train, x_test = np.expand_dims(x_train, axis=-1), np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "# check the shape of MNIST data\n",
        "print('MNIST Dataset Shapes:')\n",
        "print('x_train: ' + str(x_train.shape))\n",
        "print('y_train: ' + str(y_train.shape))\n",
        "print('x_test: ' + str(x_test.shape))\n",
        "print('y_test: ' + str(y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "jLpm2zYGjbLH"
      },
      "outputs": [],
      "source": [
        "# training parameters   \n",
        "learning_rate = 0.1\n",
        "training_epochs = 2000\n",
        "batch_size = 256\n",
        "display_step = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "PxFWmxWijbLJ"
      },
      "outputs": [],
      "source": [
        "# network parameters\n",
        "n_hidden_1 = 32\n",
        "n_hidden_2 = 64 \n",
        "n_hidden_3 = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "T7G_kreOjbLd"
      },
      "outputs": [],
      "source": [
        "# # use tf.data API to shuffle and batch data\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "3dR880IJjbLf"
      },
      "outputs": [],
      "source": [
        "# create MNIST architecture\n",
        "class ConvNeuralNet(Model):\n",
        "    \n",
        "    # set layers\n",
        "    def __init__(self):\n",
        "        super(ConvNeuralNet, self).__init__()\n",
        "        \n",
        "        # using Sequential() to avoid passing many variables in forward pass (call function)\n",
        "        # easier to edit or change the layer\n",
        "        self.model = Sequential()\n",
        "\n",
        "        # first CNN layer\n",
        "        self.model.add(layers.Conv2D(n_hidden_1, (3,3), activation=tf.nn.relu, kernel_initializer='he_uniform')) # initialize the weight matrix randomly using uniform distribution method (he_uniform)\n",
        "        self.model.add(layers.MaxPool2D((2,2))) # downsample data to half for speed\n",
        "        self.model.add(layers.Dropout(0.5)) # using dropout to make the model less rely on weight (prevent overfit)\n",
        "        \n",
        "        # second CNN layer\n",
        "        self.model.add(layers.Conv2D(n_hidden_2, (3,3), activation=tf.nn.relu, kernel_initializer='he_uniform'))\n",
        "        self.model.add(layers.MaxPool2D((2,2)))\n",
        "        self.model.add(layers.Dropout(0.5))\n",
        "\n",
        "        # third CNN layer\n",
        "        self.model.add(layers.Conv2D(n_hidden_3, (3,3), activation=tf.nn.relu, kernel_initializer='he_uniform'))\n",
        "        self.model.add(layers.Dropout(0.5))\n",
        "\n",
        "        self.model.add(layers.Flatten())  # flatten features in to a single column\n",
        "        self.model.add(layers.Dense(units = 64, activation=tf.nn.relu))\n",
        "\n",
        "        # output layer\n",
        "        self.model.add(layers.Dense(units = num_classes)) # combine to 10 classes\n",
        "\n",
        "    # set forward pass\n",
        "    def call(self, x, is_training = False):    \n",
        "        \n",
        "        x = self.model(x)\n",
        "\n",
        "        if not is_training:\n",
        "            \n",
        "            # tf cross entropy expect logits without softmax, so only\n",
        "            # apply softmax when not training.\n",
        "            tf.nn.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "YwUWeBhhjbLk"
      },
      "outputs": [],
      "source": [
        "# build Convolutional neural network model\n",
        "cnn = ConvNeuralNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "7p2CTvmajbLm"
      },
      "outputs": [],
      "source": [
        "# initialize variables with Xavier uniform\n",
        "shape = (num_features, num_classes)\n",
        "initializer = tf.initializers.GlorotUniform()\n",
        "trainable_variables = tf.Variable(initializer(shape = shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "Qdw50xjujbLs"
      },
      "outputs": [],
      "source": [
        "# Cross-Entropy loss\n",
        "# note that this will apply 'softmax' to the logits\n",
        "def cross_entropy_loss(x, y):\n",
        "    \n",
        "    # convert labels to int 64 for tf cross-entropy function\n",
        "    y = tf.cast(y, tf.int64)\n",
        "    \n",
        "    # apply softmax to logits and compute cross-entropy\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = x)\n",
        "    \n",
        "    # average loss across the batch\n",
        "    return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "sl0wEaCqjbLx"
      },
      "outputs": [],
      "source": [
        "# accuracy metric\n",
        "def accuracy(y_pred, y_true):\n",
        "    \n",
        "    # predicted class is the index of highest score in prediction vector (i.e. argmax)\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "    \n",
        "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "tBfdyTADjbLx"
      },
      "outputs": [],
      "source": [
        "# Stochastic gradient descent optimizer\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "# set up an optimization (forward propagation and backpropagation) process \n",
        "def run_optimization(x, y):\n",
        "\n",
        "    # wrap computation inside a GradientTape for automatic differentiation\n",
        "    with tf.GradientTape() as g:\n",
        "        \n",
        "        # forward pass\n",
        "        pred = cnn(x, is_training = True)\n",
        "        \n",
        "        # compute loss\n",
        "        loss = cross_entropy_loss(pred, y)\n",
        "        \n",
        "    # variables to update, i.e. trainable variables\n",
        "    trainable_variables = cnn.trainable_variables\n",
        "\n",
        "    # compute gradients\n",
        "    gradients = g.gradient(loss, trainable_variables)\n",
        "    \n",
        "    # apply the gradients to update ùúÉ and ùúÉ_0  \n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC_Ywv9LjbLy",
        "outputId": "7966b2dd-2c2c-4df1-8c29-bef0e8fb0337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step: 100, loss: 0.177339, accuracy: 0.941406\n",
            "step: 200, loss: 0.151166, accuracy: 0.957031\n",
            "step: 300, loss: 0.049901, accuracy: 0.984375\n",
            "step: 400, loss: 0.062253, accuracy: 0.984375\n",
            "step: 500, loss: 0.101288, accuracy: 0.972656\n",
            "step: 600, loss: 0.053857, accuracy: 0.988281\n",
            "step: 700, loss: 0.015418, accuracy: 1.000000\n",
            "step: 800, loss: 0.012964, accuracy: 1.000000\n",
            "step: 900, loss: 0.061007, accuracy: 0.984375\n",
            "step: 1000, loss: 0.012826, accuracy: 1.000000\n",
            "step: 1100, loss: 0.005304, accuracy: 1.000000\n",
            "step: 1200, loss: 0.018710, accuracy: 0.996094\n",
            "step: 1300, loss: 0.009381, accuracy: 1.000000\n",
            "step: 1400, loss: 0.019845, accuracy: 0.996094\n",
            "step: 1500, loss: 0.009746, accuracy: 1.000000\n",
            "step: 1600, loss: 0.024504, accuracy: 0.996094\n",
            "step: 1700, loss: 0.018120, accuracy: 0.996094\n",
            "step: 1800, loss: 0.007732, accuracy: 1.000000\n",
            "step: 1900, loss: 0.010350, accuracy: 1.000000\n",
            "step: 2000, loss: 0.013916, accuracy: 0.992188\n",
            "Test Accuracy: 0.990900\n"
          ]
        }
      ],
      "source": [
        "# run training for the given number of steps\n",
        "for step, (batch_x, batch_y) in enumerate(train_data.take(training_epochs), 1):\n",
        "    \n",
        "    # run the optimization process to update ùúÉ and ùúÉ_0 values\n",
        "    run_optimization(batch_x, batch_y)\n",
        "    \n",
        "    if step % display_step == 0:\n",
        "        pred = cnn(batch_x, is_training = True)\n",
        "        loss = cross_entropy_loss(pred, batch_y)\n",
        "        acc = accuracy(pred, batch_y)\n",
        "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))\n",
        "        \n",
        "# test the proposed model on validation set\n",
        "pred = cnn(x_test, is_training = False)\n",
        "print(\"Test Accuracy: %f\" % accuracy(pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "EJeMYCysplAm",
        "outputId": "ac604e3f-2c01-4ed6-bb4d-c0cb014ea6bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: 9\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# testing out the prediction\n",
        "img = x_test[random.randint(0, 10000)]\n",
        "plt.imshow(np.squeeze(img), cmap='gray')\n",
        "\n",
        "img = img.reshape(1,img.shape[0],img.shape[1],img.shape[2])\n",
        "pred_val = cnn.predict(img)\n",
        "print(\"Prediction:\",np.argmax(pred_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqn12Kcy50Lb",
        "outputId": "0bbe3576-a958-479e-ca9b-9790dfd2f1e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_26 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 13, 13, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 13, 13, 32)        0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 5, 5, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 3, 3, 128)         0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 64)                73792     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 167,114\n",
            "Trainable params: 167,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# model summary: 11 layers\n",
        "cnn.model.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MNIST CNN.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "bc0d9efdec36a4ba009433853d154b34a3e85cbb49bb5851e9d5bdf304782e05"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
